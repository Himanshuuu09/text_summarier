{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\OMR-09\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import math\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(filename):\n",
    "    file=open(filename,\"r\")\n",
    "    filedata=file.readlines()\n",
    "    article=filedata[0].split(\". \")\n",
    "    sent=[]\n",
    "    for sentence in article:\n",
    "        sentence=re.sub('[^a-zA-Z]',\" \",str(sentence))\n",
    "        sentence=re.sub('[\\s+]',\" \",sentence)\n",
    "        sent.append(sentence)\n",
    "    sent.pop()\n",
    "    datas=\" \".join(sent)\n",
    "    print(\"intial text:\")\n",
    "    print(datas)\n",
    "    print('\\n')\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(sent):\n",
    "    cnt=0\n",
    "    words=word_tokenize(sent)\n",
    "    for word in words:\n",
    "        cnt+=1\n",
    "    return cnt\n",
    "\n",
    "def cnt_inSent(sent):\n",
    "    txt_data=[]\n",
    "    i=0\n",
    "    for s in sent:\n",
    "        i+=1\n",
    "        data=count(s)\n",
    "        temp={\"id\":i, \"word_cnt\":data}\n",
    "        txt_data.append(temp)\n",
    "    return txt_data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dict(sent):\n",
    "    i=0\n",
    "    freq_list=[]\n",
    "    for s in sent:\n",
    "        i+=1\n",
    "        freq={}\n",
    "        words=word_tokenize(s)\n",
    "        for char in words:\n",
    "            char=char.lower()\n",
    "            if char in freq:\n",
    "                freq[char]+=1\n",
    "            else:\n",
    "                freq[char]=1\n",
    "            temp={\"id\":1,\"freq_dict\":freq}\n",
    "        freq_list.append(temp)\n",
    "    return freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf(txt_data,freq_list):\n",
    "    tf_score=[]\n",
    "    for item in freq_list:\n",
    "        ID=item[\"id\"]\n",
    "        for k in item[\"freq_dict\"]:\n",
    "            temp={\"id\":ID,\"key\":k,\"tf_score\":item[\"freq_dict\"][k]/txt_data[ID-1][\"word_cnt\"]}\n",
    "            tf_score.append(temp)\n",
    "    return  tf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf(txt_data,freq_list):\n",
    "    idf_score=[]\n",
    "    cnt=0\n",
    "    for item in freq_list:\n",
    "        cnt+=1\n",
    "        for k in item[\"freq_dict\"]:\n",
    "            val=sum([k in it[\"freq_dict\"] for it in freq_list])\n",
    "            temp={\n",
    "                \"id\":cnt,\n",
    "                \"idf_score\":math.log(len(txt_data)//(val+1)),\n",
    "                \"key\":k\n",
    "            }\n",
    "            idf_score.append(temp)\n",
    "    return idf_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfXidf(idf_score,tf_score):\n",
    "    tf_idf_score=[]\n",
    "    for j in idf_score:\n",
    "        for i in tf_score:\n",
    "            if j[\"key\"]==i[\"key\"] and j[\"id\"]==i[\"id\"]:\n",
    "                temp={\n",
    "                    \"id\":j[\"id\"],\n",
    "                    \"tfXidf\":i[\"tf_score\"]*j[\"idf_score\"],\n",
    "                    \"key\":j[\"key\"]\n",
    "                }\n",
    "                tf_idf_score.append(temp)\n",
    "    return tf_idf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(tf_idf_score,sent,txt_data):\n",
    "    # calculate the ranking of the sentence\n",
    "    sent_data=[]\n",
    "    for txt in txt_data:\n",
    "        score=0\n",
    "        for i in range(len(tf_idf_score)):\n",
    "            t_dict=tf_idf_score[i]\n",
    "            if txt[\"id\"]==t_dict[\"id\"]:\n",
    "                score+=t_dict[\"tfXidf\"]\n",
    "        temp={\n",
    "            \"id\":txt[\"id\"],\n",
    "            \"score\":score,\n",
    "            \"sentence\":sent[txt[\"id\"]-1]\n",
    "        }\n",
    "        sent_data.append(temp)\n",
    "    return sent_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(sent_data):\n",
    "    cnt=0\n",
    "    summary=[]\n",
    "    for t_dict in sent_data:\n",
    "        cnt+=t_dict['score']\n",
    "    avg=cnt/len(sent_data)\n",
    "    for sent in sent_data:\n",
    "        if sent['score'] >=(avg *0.9):\n",
    "            summary.append(sent[\"sentence\"])\n",
    "\n",
    "\n",
    "    summary=\" \".join(summary)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intial text:\n",
      "Artificial Intelligence  AI  has revolutionized many industries  and healthcare is no exception From diagnosing diseases to personalized treatment plans  AI is changing the way we approach medical care AI driven tools can analyze vast amounts of medical data to assist doctors in making more informed decisions For example  AI algorithms are being used to detect cancer in its early stages by analyzing medical images such as X rays and MRIs Additionally  AI can help optimize hospital operations  improving efficiency and reducing costs With the potential to transform patient care and reduce human error  AI is becoming an indispensable part of modern healthcare systems However  challenges like data privacy and the need for clear regulatory frameworks still exist\n",
      "\n",
      "\n",
      "Summary:\n",
      "Artificial Intelligence  AI  has revolutionized many industries  and healthcare is no exception\n"
     ]
    }
   ],
   "source": [
    "# Example of correct function calls assuming tf and idf are values\n",
    "file = clean_data(r\"D:\\\\text_summarier\\\\text.txt\")\n",
    "text_data = cnt_inSent(file)\n",
    "freq = freq_dict(file)\n",
    "\n",
    "# Ensure tf and idf are calculated and not called as functions\n",
    "tf_scores = calculate_tf(text_data, freq)\n",
    "idf_scores = calculate_idf(text_data, freq)\n",
    "\n",
    "# Multiplying TF and IDF\n",
    "tfidf_scores = tfXidf(idf_scores, tf_scores)\n",
    "\n",
    "# Ranking and summarizing\n",
    "rankings = ranking(tfidf_scores, file, text_data)\n",
    "result = summary(rankings)\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
